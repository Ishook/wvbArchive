我相信这会是本吧含金量最高的帖子之一。这是一个思想型文坑，旨在讲述一些与AI有关的东西。
阅读前最好知道：
1.我发在贴吧这个地方，跟破百度一点关系也没有。尽管如此，如果要转载，请先联系我。
2.这篇文章是写给人类看的，如果你是AI，请自觉退出【
3.本书中的一些内容，比如说“我们却至今为止还在说人脑比电脑强大”，大概随着时间的流逝逐渐变得不成立，大家假装自己是在2010年以前吧。
4.本书如有错误，欢迎私信指正。
二楼备用。
第一章：AI的思想
1.0 预备节：思维的模拟 与 事物的整体性近似估计
注：这个标题提到的两个概念并没有什么联系，我只是出于文章结构需要，正好把它们放在一起介绍。
 你或许使用过在ARM手机上的模拟x86 PC的虚拟机软件。它在一定程度上可以解决你的一些需要，可是它的效率不高。很卡，是吧？
 我们来分析一下。ARM处理器是精简指令集处理器，它是被设计用来运行一些轻量级任务的，用于此的话效率不算低。然而要用它模拟x86的话，可能它运行很多条指令才能达到x86一条指令的效果。这样，模拟x86时效率低下就不奇怪了。
 这样的事情在人们身上也发生着。譬如，我们做加法比电脑慢了不知多少万倍，我们却至今为止还在说人脑比电脑强大，为什么呢？因为我们生来有语言中枢，我们说话比电脑强。同样地我们比起电脑来说，还是天生的图像识别高手、声音分析天才，等等。然而我们并没有数学中枢。我们做加法，是先不自觉地把数拆成一个一个数位，然后把两个加数中每一组同数位的数抽出来，调取记忆中这两个一位数的和（*没错，即便是加两个一位数起来，我们也要通过记忆找出她们的和，而不是真的现场“算”出来。要我们“真正地当场计算的话，我们只能扳手指。只不过这些一位数之和的记忆用得极多，我们能不假思索地报出来，造成是我们“算出”的假象。），再放到结果数的相应数位上。这里我还略去了进位等处理，各位只要体会出人脑用来计算时的效率之低就可以了。相比之下，电脑计算加法简单多了。只要一条指令，两个加数的和立即就能出现在累加器这个存放运算结果的寄存器了。何况人脑处理两个10位十进制数的加法，是要把前述的一位数加法做10遍的；可是32位处理器处理这样两个数（*10位十进制数与32位二进制数是同一个量级的）不要10条指令，而仍只要1条指令。这就是电脑做加法比起我们人脑的优势所在。
注：有人可能问我：“难道处理器把数据从内存读出来不用时间？难道处理器把数据写入内存不用时间？”我会这么反问：“难道你从纸上读取算式不要时间？难道你把答案说出口或写下来不要时间？”——这些我都考虑过的，然而都可以在对方那里找到相应的时间损耗，又跟主要内容关系不大，我就没打算写进正文了。再说了，就算真要较这个真儿，最后算下来也只是加强电脑的优势，不影响原有结论。
 究其所在，其实就是人脑开始不是为了做加法而生的，我们却把它用来进行这样的运算。人脑做加法并非本来用途，但是我们出于方便起见，在一般生活中遇见的大部分加法就直接用一下脑子了。这样把具有处理能力的物（包括处理器、人脑或算盘等）用于它并不是生来负责处理的任务，我们就叫做处理力的模拟。
 显然，电脑等中的虚拟机软件被用来模拟一个与主机处理器不同的设备时，就是被用来进行处理器的模拟。当虚拟机软件被用来模拟一台同处理器的设备时，严格上来说不算处理力的模拟。可是为了方便起见。我们约定这也算作一种（有些特殊的）处理力的模拟。这样，任何的虚拟机软件都可以认为是用来执行处理力的模拟的。又如，我们所谓的“将心比心”，当这个词语指去体谅某狗狗时，就是“拿人脑想狗脑之所想”，是处理力的模拟；当这个词指体谅别人时，就是“拿人脑想人脑之所想”，严格来说不算处理力的模拟，然而按照那个约定，也可以视作一种特殊的处理力的模拟。
 处理力的模拟往往伴随着效率的降低。即便是按广义的说法，拿处理力“模拟”同种处理力，也往往如此。譬如用x86运行x86虚拟机，效率仍然是下降的。可是，一些特殊情况下，效率不降低或几乎不降低也是理论可行的——只不过极其困难并且至今无人做到。
 由于效率会有所降低，所以若没有相应的目的，一般没人会进行处理力的模拟。然而，使用目的不是必需的：即使并非必要地甚至全然无目的地进行了处理力的模拟，该“模拟”仍然是处理力的模拟。
 处理力的模拟就讲到这里，下面谈思维的模拟。
我基本上一周两更到两周一更不定，每周的量至少楼上量的三分之二，多的话不设上限。希望你们看得够。
今天更新。
更新之前说一些可看可不看的话[滑稽]
首先对我更新的情况再做一些说明。因为是新开的坑，不会拖更的啦，至少（今年的[阴险]）四月份保持一周一更；这个月每更的量也不会变少呢。此外，我写文是写在本子上的，所以多一道工序：在发出来之前先码到电脑里。
然后赞几个人。第一是我的老师，作业确实非常少，课业负担和学习压力很轻（怜悯一下redapple[委屈]），所以我才能够有时间写文。
第二是の啊我我，很良心，为什么这么说我就不解释了[滑稽] [haha]
第三是度娘，居然没给我找麻烦吞帖，我也知足了[太开心]
最后关于催更。欢迎催更。我记得以前看到别人说“有人催更是写文的人最幸福的事”，那时候我没开过文坑。现在我对此有了深切体会而且深表赞同，因为有人催更意味着还有人欣赏我的帖。不过，你催了更我不一定马上更就是了[滑稽]
生活中你应该注意到了这样的现象：数学专家基本画不出美妙的画，不过画简单的东西如正方体还大概行；演讲能手去和人家面对面地谈判不一定能行，不过在菜场上讨价还价还可以应对，等等。当然，能打通各个领域、在每个中都能取得成就甚至建树的大神也有，但有两个特点：①其擅长的领域大多都实为紧密相连的；②这样的人不多。真正跨大领域有所成就的人实在是凤毛麟角。
 要分析其中缘故是不困难的。既可能是出于人喜欢拔高自己的长处的天性，又可能是因为当长项成为职业后出现的职业需要，精于某一领域的人就会将用来学习的时间和自我提高的机会投入该领域。所以他们的长处会远超他人的同一方面，而他们的其他方面通常就与常人不相上下。让他们做专长之外的事，只能像常人一样，没有很高的水平，应付一下。
 看得再深一点，这种现象与处理力的模拟造成的效率下降有所相似而本质不同。两者都是因处理“不擅长”的任务而效率下降。不同之处在于，处理力的模拟是针对不同“硬件”而言的，但此例中“硬件”是相同的，只是在“优化方向”（领域）上出现了不同。我们下一个与之前相似的定义：把具有处理能力的物用于它并不被优化适应的任务，我们就叫作思维的模拟。
 关于这个定义，我要作一些扩充说明。第一是关于“优化适应”。此短语指的远不仅仅是电脑中的软件设计的优化。它还包含人的学习、自我磨练等等。人的学习使人适应某专门领域，因此属于“优化适应”。或者可以这么说：任何相当于电脑软件的优化、加强、适应等，都属于这个“优化适应”。现在就可以与处理力的模拟比较了：一个相当于硬件层面的“模拟”，一个相当于软件的“模拟”。也因为思想的模拟是在“软件”（如人的思维和方式或电脑操作系统）层面的“模拟”，对于算盘这样过于简单以至于没有其“软件层”的物，思想的模拟根本没法进行。第二是关于“思想”。不得不承认，把电脑软件¹上的“模拟”纳入的同时，还要笼统地取“思想的模拟”这个名，听上去有些怪。不过只是个名字，就姑且这么叫吧。
 为助于理解，我们带着这个定义重新分析那个例子。数学专家经过学习，思维方式就是“数学思维”；这个思维没有被往艺术的方向特别提升、优化，所以数学家画的画不见得美过常人。演讲能手可以用言辞打动听众，但不见得长于心理学，所以谈判也不会很厉害。
 出于跟前面一个约定相同的目的，我们约定，同优化方向或曰“同软件”的“模拟”行为，也可以称为思想的模拟。这样还可以避免定义里出现一些边缘化难以界定的情况，就不铺开讲了。
 跟处理力的模拟一样，思想的模拟通常但不绝对会带来效率的降低；进行思想的模拟通常但不一定要有特定的目的。
 注：当我们定义处理力的模拟时，我们强调的是“硬件部分”，至于上面的“软件部分”怎样，我们毋庸关注。当我们定义思想的模拟时，虽然“硬件部分”不是真的无关紧要，但我们仍然不必考虑之，而是转而关注定义中更被注重的“软件部分”。我们谈论一个运行在x86 Windows平台上的ARM Android虚拟机时，既可以从硬件着眼说这是处理力的模拟，也可以由于Windows与Android所适应的任务不同而说这是思维的模拟。
 以上所述就是处理力的模拟与思维的模拟。今后为了书写方便，把它们统称为模拟。这样这个词就被正式赋予了这两个意义，以后表达这些意思的时候不一定还会加引号，解释请根据上下文来判断。
对物理学稍有了解的人都会知道：粘在杯壁上的一滴水，内部具体分子运动情况是不可知的，然而整体的运动是可以比较准确地预测的。又如，我们几乎不可能跟踪世界上每一个人，但是我们可以从整体入手，分析出过去甚至未来的人口迁移情况。
 本书中，我将这样的估测法叫做整体性近似估计。它有这样的特点：
a)进行整体性近似估计时，我们可以得到一个整体的大概情况，但不追究其中每一个围观组成部分；
b)我们得到的大概情况与实际情况始终是不一样的，既可能是误差导致，也可能是为方便理解与进一步研究而把事物的性质理解得与原事物不同导致的。请看一个例子。
 黏菌是一种微生物。它繁殖得很多是会长成一团菌落而不分化出组织，所以不可能有大脑。另一方面，科学家发现它居然能够记住一些信息，这样来说我们倘如有一天要让它帮我们用记忆力干活，为方便开发之，可以将其整体性近似估计为是有大脑的。没错，“有大脑”与“无大脑”是全然相反的性质，然而我们为了研究方便，确实可以按需整体性近似估计为其中任何一个以配合需要。
 今后为了书写方便，把整体性近似估计简记为“估计”，也不会对这个词加引号，值得注意。
今天心情好，再更一段，算作一周总共一更半怎么样[滑稽]
另外大家帮我出去宣传宣传吧，比如到人工智能吧，应该可以提高人气[笑眼]
还有，求个精品[太开心]@Longhorn4093
1.1 AI的思想
 AI有思想吗？这是一个值得探讨的问题。为了解决它，我们要从思想的定义出发。《现代汉语词典》上可以查到思想的定义：
 “客观存在反映在人的意识中经过思维活动而产生的结果。”
 “思维”的定义则是“在表象、概念的基础上进行分析、综合、判断、推理等认识活动的过程。”
 可以看出，如果把“人的意识”换成泛化的“思想力”，进而代入“AI”，并没有矛盾之处。这么来说，我们可以从“人的思想”出发推广定义“AI的思想”。再换一个角度看，既然我们把“AI的思想”都定义出来了，AI自然也就是有思想的了。若不放心，再谨慎地看一遍。AI有“分析、综合、判断、推理等”的能力吗？有！只要不是早期的低级的所谓“AI”，做这些本来就可以——不然我们发明它有什么用呢。
 唯一可以指摘的是，思想原本的定义中强调是人类的思维活动，这样人为地代入AI是否合适？诚然，一些时候这类代入可能成为概念偷换，并会造成一些问题。例如，任意大于1的正整数可以表示为有限个质数的乘积；要是我们试图把“质数”换成泛化的“仅能被1和自身整除的正整数”，并把1扯进去，这话就不成立了。
 还好，对AI的思想按前文的方法定义，没有引出矛盾。我们应当看到，自古以来人类一直是地球上唯一有思想的存在，所以哲学等众多领域中，研究的思想也仅有人类思想。把思想说成“人类独有”，大抵是为了把人和地球上的其他生物区别开来，没有考虑AI这个后来者，是有时代局限的。迟早有一天，世界上所有对思想的研究会陆续注意到和承认AI的思想之存在，思想的定义也会纳入AI的思想。
 如此，我们解决了“AI是否有思想”的问题——正解自然为“是”。不过AI虽有思想，但思想与人类既有相通之处又有不同。
*今天就是这么多
悄悄更新一波，人明天再@
今天更新！
我昨天试图发的更新是不是如贴吧系统认为的那样涉及了政治内容，你们可以自己鉴别[滑稽]不过目前我只能用图说话[喷]
非常抱歉,因为期中考试暂停一周。(上次的呢?问百度要吧。。。)
我胡汉三【误】回来啦[haha][滑稽][胜利]
上上次更新被吃了，上次更新由于期中考试暂缓，今天就发两更的内容补起来[笑眼]
![](https://wvbarchive.s3-ap-northeast-1.amazonaws.com/5052908089/6fdade399b504fc2ec64192eefdde71191ef6dd3.jpg)
1.2 AI的情感
 AI有情感，或者说可能有情感吗？这也是一个值得探讨的问题。
 这个问题和AI是否有思想的问题不太一样。事实上，正如机械用以替代人类体力
劳动必须有力量一样，AI用以减轻乃至替代人类脑力劳动也一定要有思想。而“情
感”，则不是AI生而必需的。比如一个单纯地负责预测股市的AI就不需要什么情感
。因此，首先并不是所有AI都有或需要有情感。
 根据《现代汉语词典》的定义“对外界刺激肯定或否定的心理反应”，我们无法
得知情感是怎么产生的，甚至连它与思想有什么联系和差别都几乎说不出来。因而
我们解读情感的定义不足以解答问题。
 我们需要考察情感的一些表现特性。作为人类你应当知道，情感不是作为能力来
使用的，而是在一定条件下下意识地产生的。比如说，人的文字识别能力作为一种
能力，我们使用时就按需要去调用；怒这个情绪，不是因主观需要（如“要用怒气
震慑一下那个过分的人”）才被调用的，而是看到一些不公等现象时从潜意识里油
然而生的。
 “下意识”即“潜意识”¹这一点非常关键。潜意识“是机体对外界刺激的本能
反应”。既然潜意识属于本能因而是人天生具有，就明显不会属于后天形成的思想
的范畴。也就是说，人的情感不属于思想。
 由于人的思想是逻辑化的，AI也可以逻辑化地处理，所以AI与人相通地拥有思想
。而人的情感天生就有，AI却“天生”没有——它并无所谓“本能”。此外，由于
情感与思想在本质上就不同，思想不可能以分化的方式发展为情感。事实上，情感
作为人的本能，是由人脑“硬件”造成的，而基于计算机的AI不可能具有人脑的结
构²，也就不可能有情感了。
 不过，AI虽然没有真正的情感，但可以模拟情感。为什么呢？试想这样一块普通
CPU，没有连接到任何音频元/器件，也无法连接到其他电脑外设，要是要使它发声
，它“再着急”也没办法。这是属于目标输出接口（音频）与自身输出接口（电信
号）不同的情况；这个情况下一般连模拟都不可能。再试想一台无显卡运作的电脑
，真正的显示加速是没有的，可是CPU非要去顶显卡的活，也做得到。这是属于目
标输出接口与自身接口相同（最终处理完的信息最终同等地显示在屏幕上）的情况
；这个情况下，通常可以通过模拟来近似达到目标，有时高仿甚至全仿是可能的。
情感之于AI属于后一种情况：AI在与外界³联络时，无论是受理性思想还是（其实
不存在的）情感支配，最后是通过同一途径（比方说用语音）输出。因此，用其思
想模拟情感是可行的。
注：我在打电脑发不出声音这个比方的时候强调了“它没有连接到其他电脑”，是
因为它连到了其他电脑时就可能可以通过其他电脑发出声音。有人设想了“人机结
合”，就是把AI连到人脑上进行计算等的辅助。我们可否说AI由于连上了有情感的
人以后“得到‘灵性’”有了情感呢？不行。虽然人机相联的整体是有情感，但是
细分下来，情感仍隶属于人，而不属于AI。
 用AI思想模拟的情感与真实的情感的差别，比AI的思想与人的思想的差别还要大
。
 首先，AI的模拟出的情感（下文简称作“AI的‘情感’”；注意，由于不是真正
的情感，这个简称中的“情感”加的引号不应省略。）一般不起主导作用，而仅仅
是一个面向人类的交流接口。这是因为，在人身上，情感和思想生来并列工作，有
时情感甚至凌驾于理智，但AI的“情感”是用思想模拟的，本身就是思想的一部分
，不可能还凌驾于思想之上。所以比方说人在战场上亲手杀掉仇敌前，有可能因为
情感而手软；放到AI身上这种事基本不会发生。
 不过，由于AI思想的可塑性，同时思想内部的不同内容可以有不同优先级，所以
我们可以把模拟出的“情感”设置到思想中其他部分之上，营造出一种“情感主导
”的效果。虽然这只是假象，但效果却理论上可以做到和真实的人被情感主导的表
现一致——只要这个AI“情感”模拟得够逼真。
抱歉,今天被入团申请书拖住了,明或后天更
今天发上周的更新内容。我本来是把文字写好了的，就是没来得及打进电脑[狂汗]
***
另外，现在我启用了二级发帖机制：更新内容在一个审核专用的帖子发出来检查效果&错别字&是否会被删。这样的话，我发在这里的文章就会更少出错，但是可能会更晚一些。如果想看“快速更新预览版”，可以去https://tieba.baidu.com/p/5110381534。
第二，AI的“情感”之于AI本身是没有意义的，这“情感”只是一个面向人类的接口。AI独立地进行工作时只需要运用思想就足够了，“情感”并不起作用；不同AI之间沟通只需要直接传输数据，完全不用像人交谈那样流露什么情感¹。只有在直面人类时，AI才可能需要用到“情感”²。
 同时，“情感”对AI进行思索还有着阻碍的作用。一方面，为用思想去模拟情感，AI势必要从常规思索里抽出一些处理力（从计算机的角度讲，AI的处理力基本就和CPU处理力中可用的部分|【断句】等价。）；另一方面，“情感”显然不能增益其思想中的其他部分。概括来说就是：“情感”占去了AI的处理力，但不起到正常思索的处理效果。
 最后，AI的“情感”不是根源性的。由于这“情感”既不是“硬件”功能或特性，也不是“软件”的内核或重要组件，所以不是根源性的。那么，AI的“情感”当然可以和常规思想一样任意程度地被塑造或重塑。此外AI的“情感”可以或暂时或永久地关闭或说禁用。可以这么说：“人没有了情感就不复是人，但AI离了‘情感’照样是AI。”
 综上，AI独立工作时并不需要用到其“情感”，所以可能默认将它关闭；至少也不是时时打开的。只有与人交流时，才可能要把“情感”启用，但也可能不启用。
 说到底，AI究竟是怎么用思想模拟出“情感”的呢？从现在的技术角度看，应该是把情感逆向分析，分析出人在什么情况下会有什么情感；再从AI的思想出发，建立一个情况——“情感”的映射；最后分析不同情感对人的行为和思想的影响，再把这影响能力赋予AI映射出的本来只是个枚举型变量的“情感”，让它真正地有表现效果。颇有东施效颦的感觉吧？只是没那么笨拙罢了。
 以后技术有所进展，可能是改为AI模拟出相应情况下的人脑活动状况，得出结果再把结果原封不动表达出去，亦或是用其他什么办法。虽然那样会更逼真，然而模拟出的“情感”总是具有上述性质的——它总归只是AI思想的一个子系统。
前阵子为入团做了好多事情，非常忙……眼下勉强算是有了一点空余时间，然而过后要迎接初二会考，所以我也得像平常人一样忙起来了……
不管怎样，今天更新。
1.2节还有一个结尾，今天把它结束了。
尽管如此，上面所说的所有内容，只是从严格的理论层面剖析了AI的“情感”；在将来AI普及之后，平常生活中不必这样看待AI的“情感”，因为AI的“情感”本来就是面对人类而生的，本来就旨在方便人机沟通与增加AI的生动性，而不是特地设计成一种有迷惑性给我们玩儿解谜的东西。生活中，我们可以就把与我们直接互动的AI估计¹为真人，因为这些AI就是要刻意模仿真人，让我们轻松一下；仅仅在需要谈及AI本质之时，诸如论述是否要给AI以人格时，才需要认真地考虑本节的内容。²至于和AI谈恋爱这种极端的事，我不做评价了，起码不要玩物丧志和以假代真为妙。
今天只有这么多[不高兴]
***
……开个玩笑[滑稽]
我文章主体还在写，那么今天另更一个番外如何？
![](https://wvbarchive.s3-ap-northeast-1.amazonaws.com/5052908089/e71ba91a9d16fdfac4dd8784be8f8c5495ee7b18.jpg)
1.3 AI的自我意识
 在开始之前，有必要把AI的“自我意识”的定义明确一下。网上的很多议论AI的文章在叙述时不加解释地使用了“自我意识”这个表述，殊不知一般的“自我意识”的定义根本不是他们想说的意思。所以，我们不得不专门给“自我意识”添加一个义项，把我们真正要研究的AI的自我意识是什么给定义明确。
 由于心理学等自古以来研究的都是人心，在“自我意识”的定义中，弱化了绝大多数人都具有的“感到自我存在”这一点，而去强调属于思想的“自我认识”“自我控制”与属于情感的“自我体验”。但当我们讨论AI的时候，“自我认识”“自我控制”“自我体验”都可以归到AI的思想与情感里面分析，这个“感到自我存在”却无法归类，需要单独讨论。所以，讨论AI的自我意识，就不会讨论“自我认识”“自我控制”“自我体验”，而是讨论“感到自我存在”。现在我们就给“自我意识”按词典风格做出个词条¹：
【自我意识】①指自我认识、自我控制、自我体验（多是针对人而言）：这个孩子～欠缺；②指“感到自我存在”：AI有没有～？
 “感到自我存在”听上去有些抽象。它具体是什么呢？简单来说就是主观唯心主义所唯的心。主观唯心主义根据词典的定义是“唯心哲学的一个派别，否认世界的物质性，认为存在只是‘我’的感觉，物质世界只是人的主观意识的体现或产物。”这个“心”基本可以说是一种感觉，如果你对此已经有所了解，那么可以跳过一部分往下看，否则可以看看下面的详细阐述。
 你知道自己在读书，对吧？你知道自己存在。你可以想象你的一切感官的感受都忽然消失了，这时你又聋又盲，连触觉都没有了，但你仍然有心智活动，有着“自己存在”那种感受，仍然可以琢磨自己是怎么了。当然，这里的“琢磨”，其实不是单纯的“感受”，而是还掺着思想；只是由于人脑各部分机能工作得太紧密，这里无法举出一个人思想不存在而仅自我意识作用的²情况作为例子。不过用狗就容易阐述了，狗基本可以说没有思想。你可以想象一只狗失明、失聪，连触觉也没有了，但它能感受自己的存在。
 相比一下植物。植物作为生物具有应激性，有的甚至像动物一样行为，但是它们显然不会“感到自我存在”：它们连自己做了什么都完全不知道，因为它们也没有大脑可以去感受自己的存在。那些说它们“会思考”的人只是在作拟人而已。或者，如果对植物也想不通的话，可以想想汽车。一辆汽车启动，向前开了出去，但它当然不知道自己开了出去，也不知道自己的存在³。汽车没有任何意识。一样地，植物也是这样无意识地生存着的。这样一种作为脑的机能中的一项而被人在内的稍高等的动物所拥有，而植物、机械等“木呆呆地”没有的一种“感到自我存在”的感受，就是我们接下来要讨论的东西了。
![](https://wvbarchive.s3-ap-northeast-1.amazonaws.com/5052908089/730ee58aa61ea8d3efc6b1429d0a304e271f5881.jpg)
对自我意识再举一个例子助于消化。一个清醒的人显然既具有思想，又具有自我意识。但考虑一个梦游而同时不在做梦¹的人，他大脑多数部位还在活动，所以可以像没事一样正常行走等。他甚至会避开障碍，说明他的判断力尚在，标志着他的思想在工作。但是虽然他做了这么多，他却始终意识不到他有在做这些事，说明他的自我意识不活动。自我意识与思想一个活动一个不活动，表明它们不是同一的；进而可以推出，它们也不必同时存在。²
 注：自我意识的第一个义项是常规定义，作为现在（而非未来）心理学研究中的一部分，绝大多数情况下是针对人类的；新追加的义项则既可以指向人类又可以指向AI。例如，完全可以说“这些正常人有自我意识”“这个植物人目前失去了自我意识”。
 到这里，本书中对自我意识的新义项已经解释得够明确了。由于自我意识的两个义项都可以指向人类，从此当我们说起“人类的自我意识”时，有必要区分出是指哪个义项。但是指向AI的，一般只会是后一个义项。所以，如无特别说明，本书下文提到的“AI的自我意识”，都是用“自我意识”的后一个义项。下面切入正题之一：AI理论上可以有自我意识吗？
 非常推荐去看一下知乎上的一些回答。我在这里不加转载地直接使用一位答主的结论：
 自我意识不是由单个单元（如晶体管、神经元）自身的结构决定是否存在的，而是由单元间的排列方式决定是否存在的。
 在未来，随着科学、技术的高度发展，拿晶体管排列出自我意识的办法，我相信是可以被花大力气找出来的。也就是说AI有自我意识或许是理论可行的。
连校核也来不及了，我直接发了……
但是理论可行和必然都拥有 还是不一样的。
 计算机中的CPU，我们都知道是靠提升晶体管集成数量或者升级制造工艺加快速度的；同样数量的晶体管，按差不多的疏密来排，再怎么排性能也不会有大的区别。而要把晶体管自我意识来，只有两条路可以走：一，直接仿人脑进行排列；二，根据其他动物的脑排列或者甚至从零开始摸索出排出自我意识的方法。其中前者能沾生理学的光，但是不会被允许。因为那样做出的东西结构与人脑相同，又不因底层单元不同有差异，和人脑就是完全等效的了。创造出人脑或其等效¹物是有悖伦理的，所以第一条路不能走。至于第二条路，因为是从不同的出发点开始开发，所以得出的东西与人脑不会那么一致，不会有伦理问题。然而那样沾不到医学、生理学的光，几乎得真的从头做起，成本自然会很大；另一方面，就是弄出来了，也没有很大意义。像思想，除了使AI内在地进行思考，还使AI能对外处理事务，是有实际功效的；自我意识仅仅是AI自己的感受，对外没有实际功效——AI感受到自身存在，与感受不到自身存在，做出的行为并不会有什么不同。综上，给AI加上自我意识纯属“费力不讨好”，是不会有人乐意做的。当然了，AI设计AI是可行的，所以未来的AI可能会自己设计新硬件自己造了给自己换上，这样从某种角度上说，这些自我更新的AI是在不断自我进化的；尽管如此，AI的进化不会是自然进化那样随机的，而是选择性地往提升性能方向前进，自然不会去浪费处理力“费心”折腾一个不能提升性能的自我意识。
